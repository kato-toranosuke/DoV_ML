import numpy as np
import pandas as pd
from typing import List, Any, Union, Dict
from sklearn.impute import SimpleImputer
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import MinMaxScaler
import pprint
from sklearn.ensemble import ExtraTreesClassifier
import joblib
from sklearn.model_selection import cross_val_score, cross_val_predict
from sklearn.metrics import confusion_matrix, f1_score
from sklearn.ensemble import RandomForestClassifier


CSV_PATH = "../out/csv/"


def CsvToDf(csv_list: List) -> pd.DataFrame:
    df = pd.concat([pd.read_csv(CSV_PATH + filename) for filename in csv_list])
    return df


# 読み込むCSVファイルのリスト
csv_list = ["fearures_mono_ch_complete_211007.csv"]
df = CsvToDf(csv_list)


# session1のデータの抽出(式を評価するengineとしてnumexprを使用することで、処理の高速化を狙う。)
train_set = df.query('session_id == "trial1"', engine='numexpr')
test_set = df.query('session_id == "trial2"', engine='numexpr')


class DataFrameSelector(BaseEstimator, TransformerMixin):
    '''
    DataFrameから、属性を選択し、Numpy Arrayへ変換する変換器。
    '''

    def __init__(self, attribute_names: List) -> None:
        self.attribute_names = attribute_names

    def fit(self, X: pd.DataFrame, y=None):
        return self

    def transform(self, X: pd.DataFrame) -> np.ndarray:
        return X[self.attribute_names].to_numpy()


class ValueTransducer(BaseEstimator, TransformerMixin):
    '''
    値を他の値に変換する。
    '''

    def __init__(self, vals) -> None:
        self.vals = vals

    def fit(self, X: np.ndarray, y=None):
        return self

    def transform(self, X: np.ndarray) -> np.ndarray:
        X_ = []
        # Trueになる値->1, それ以外->0
        for val in self.vals:
            x_ = np.where(X == val, 1, 0)
            X_.append(x_)
        # ndarrayに変換
        X_ = np.array(X_)

        # 1次元配列にまとめる
        label_list = []
        for i in range(len(X)):
            bool = X_[:, i].any()
            label_list.append(int(bool))
        # ndarrayに変換
        label_np = np.array(label_list)

        return label_np


# 特徴量に該当する列の抽出
feature_attribs = ['low_power', 'high_power', 'hlbr', 'coe1[0]',	'coe1[1]', 'coe3[0]', 'coe3[1]', 'coe3[2]',	'coe3[3]', 'ratio_max_to_10ms_ave_peaks', 'ratio_max_to_9th_ave_peaks', 'ac_std', 'ac_auc', 'diff_std', 'diff_auc',	'srmr', 'gp_max_val_std', 'gp_max_val_range',
                       'gp_max_val_min', 'gp_max_val_max', 'gp_max_val_mean', 'gp_max_ix_std', 'gp_max_ix_range', 'gp_max_ix_min', 'gp_max_ix_max', 'gp_max_ix_mean', 'gp_auc_std', 'gp_auc_range', 'gp_auc_min', 'gp_auc_max', 'gp_auc_mean',	'tdoa_std', 'tdoa_range', 'tdoa_min', 'tdoa_max', 'tdoa_mean']


# pipeline
features_pipeline = Pipeline([
    ('selector', DataFrameSelector(feature_attribs)),
    ('imputer', SimpleImputer(strategy="median")),
#     ('min_max_scaler', MinMaxScaler())
])


X_train = features_pipeline.fit_transform(train_set)


X_test = features_pipeline.fit_transform(test_set)


# 正解値labelを生成するpipeline
label_attrib = ['dov_angle']
facing_dov_angles = [0, 45, 315]


label_pipeline = Pipeline([
    ('selector', DataFrameSelector(label_attrib)),
    ('transducer', ValueTransducer(facing_dov_angles))
])


y_train = label_pipeline.fit_transform(train_set)
y_test = label_pipeline.fit_transform(test_set)


# 交差検証の結果を表示する
def display_scores(scores):
    print("Scores: ", scores)
    print("Mean: ", scores.mean())
    print("Standard deviation: ", scores.std())


from sklearn.model_selection import GridSearchCV


param_grid = [
    {'n_estimators': [2, 10, 100, 1000], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 5, 10], 'max_features': ['sqrt', 'log2', None], 'bootstrap': [False], 'n_jobs': [-1], 'random_state': [42], 'max_samples': [0.01, 0.5, 0.09]},
    {'n_estimators': [2, 10, 100, 1000], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 5, 10], 'max_features': ['sqrt', 'log2', None], 'bootstrap': [True], 'oob_score': [True, False], 'n_jobs': [-1], 'random_state': [42], 'max_samples': [0.01, 0.5, 0.09]}
]


ext_clf = ExtraTreesClassifier()
ext_grid_search = GridSearchCV(estimator=ext_clf, param_grid=param_grid, scoring=['accuracy', 'balanced_accuracy', 'f1'], n_jobs=-1, refit='accuracy', cv=5, return_train_score=True)


ext_grid_search.fit(X_train, y_train)


cvres_grid_search = ext_grid_search.cv_results_
pd.DataFrame(cvres_grid_search)[:10]


ext_grid_search.best_params_


ext_grid_search.best_score_


# モデルの保存
joblib.dump(ext_grid_search.best_estimator_, './pkl/ext_best_estimator_gridsearch_211008_1.pkl')


ext_clf = ext_grid_search.best_estimator_


ext_clf.score(X_test, y_test)


# K分割交差検証
y_test_pred = cross_val_predict(ext_clf, X_test, y_test, cv=3)
confusion_matrix(y_test, y_test_pred)


f1_score(y_test, y_test_pred)


# for ext_best_estimator_gridsearch_211012_1.pkl
param_grid = [
    {'n_estimators': [5, 10, 20, 30, 40, 50, 60], 'min_samples_split': [2, 3, 4], 'min_samples_leaf': [3, 5, 8], 'max_features': [None], 'bootstrap': [True], 'oob_score': [True],'n_jobs': [-1], 'random_state': [42], 'max_samples': [None, 0.09]}
]

# best params
# {'bootstrap': True,
#  'max_features': None,
#  'max_samples': 0.09,
#  'min_samples_leaf': 5,
#  'min_samples_split': 2,
#  'n_estimators': 10,
#  'n_jobs': -1,
#  'oob_score': True,
#  'random_state': 42}


# for ext_best_estimator_gridsearch_211012_2.pkl
param_grid = [
    {'n_estimators': [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16], 'min_samples_split': [2], 'min_samples_leaf': [4, 5, 6, 7], 'max_features': [None], 'bootstrap': [True], 'oob_score': [True],'n_jobs': [-1], 'random_state': [42], 'max_samples': [0.09]}
]

# best params
# {'bootstrap': True,
#  'max_features': None,
#  'max_samples': 0.09,
#  'min_samples_leaf': 5,
#  'min_samples_split': 2,
#  'n_estimators': 7,
#  'n_jobs': -1,
#  'oob_score': True,
#  'random_state': 42}

# result
# 0.7395833333333334
# array([[2707,  893],
#       [ 905, 1255]])
# f1: 0.5826369545032497


ext_clf = ExtraTreesClassifier()
ext_grid_search = GridSearchCV(estimator=ext_clf, param_grid=param_grid, scoring=['accuracy', 'balanced_accuracy', 'f1'], n_jobs=-1, refit='accuracy', cv=5)
ext_grid_search.fit(X_train, y_train)


ext_grid_search.best_params_


joblib.dump(ext_grid_search.best_estimator_, './pkl/ext_best_estimator_gridsearch_211012_2.pkl')


ext_clf = ext_grid_search.best_estimator_


ext_clf.score(X_test, y_test)


y_test_pred = cross_val_predict(ext_clf, X_test, y_test, cv=3)
confusion_matrix(y_test, y_test_pred)


# 交差検証
scores = cross_val_score(ext_clf, X_test, y_test, scoring="accuracy", cv=10)
display_scores(scores)


# 交差検証
scores = cross_val_score(ext_clf, X_test, y_test, scoring="accuracy", cv=3)
display_scores(scores)


f1_score(y_test, y_test_pred)


param_grid = [
    {'n_estimators': [2, 10, 100, 1000], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 5, 10], 'max_features': ['sqrt', 'log2', None], 'bootstrap': [False], 'n_jobs': [-1], 'random_state': [42], 'max_samples': [0.01, 0.5, 0.09]},
    {'n_estimators': [2, 10, 100, 1000], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 5, 10], 'max_features': ['sqrt', 'log2', None], 'bootstrap': [True], 'oob_score': [True, False], 'n_jobs': [-1], 'random_state': [42], 'max_samples': [0.01, 0.5, 0.09]}
]


rnd_clf = RandomForestClassifier()
rnd_grid_search = GridSearchCV(estimator=rnd_clf, param_grid=param_grid, scoring=['accuracy', 'balanced_accuracy', 'f1'], n_jobs=-1, refit='accuracy', cv=5, return_train_score=True)


rnd_grid_search.fit(X_train, y_train)


feature_score = {}
for name, score in zip(feature_attribs, ext_clf.feature_importances_):
    feature_score[name] = score
    
# sort
feature_score_sorted = sorted(feature_score.items(), key=lambda x:x[1], reverse=True)
pprint.pprint(feature_score_sorted)
