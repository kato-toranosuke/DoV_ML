import cis
import numpy as np


# 音声データの読み込み
v, fs = cis.wavread('/Volumes/GoogleDrive/マイドライブ/Research/Project/DoV/dataset/s1/s1_downstairs_nowall_trial1/A0_1_0/recording0_0_0.wav')
# 時間軸の設定
dt = 1/fs
t = np.arange(0,len(v)/fs, dt)


type(v)


len(v)


v.shape


v2, fs2 = cis.wavread('/Volumes/GoogleDrive/マイドライブ/Research/Project/DoV/dataset/s1/s1_downstairs_nowall_trial1/A0_1_0/recording0_0_1.wav')
dt2 = 1/fs2
t2 = np.arange(0, len(v2)/fs2, dt2)


import matplotlib.pyplot as plt
import scipy.fftpack as sfft
import matplotlib.mlab as mlab
import scipy.signal as ss


N = 2**12
cs = sfft.fft(v[:N])

# x軸の定義
hz_delta = fs/N
x = np.arange(0, fs/2, hz_delta)

# 描画
plt.xlabel('Hz')
plt.plot(x, np.abs(cs[:int(N/2)]))
plt.show()


# 閾値となる周波数に対応するインデックス
th = 7000
index = int(th/hz_delta)
power = np.power(np.abs(cs), 2)


low_power = np.sum(power[:index])
low_power


high_power = np.sum(power[index:])
high_power


hlbr = high_power / low_power
hlbr


N128 = 128
cs128 = sfft.fft(v[:N128])
cs128_abs = np.abs(cs128[:int(N128/2)])

hz128 = np.arange(0, fs/2, fs/N128)


# 描画
plt.xlabel("Hz")
plt.plot(hz128, cs128_abs)
plt.show()


# 関数フィッティング
from scipy.optimize import curve_fit
import seaborn as sns


def linear_fit(x, a, b):
    return a*x+b


param, cov = curve_fit(linear_fit, hz128, cs128_abs)


param


cov


# フィッティングの結果
plt.plot(hz128, cs128_abs)

y_linear_fit = param[0]*hz128 + param[1]
plt.plot(hz128, y_linear_fit)

plt.show()


coe = np.polyfit(hz128, cs128_abs, 1)
print(coe)


# 結果の表示
plt.plot(hz128, cs128_abs)

linear_fit_res_polyfit = coe[0]*hz128 + coe[1]
plt.plot(hz128, linear_fit_res_polyfit)

plt.show()


from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression

poly_features = PolynomialFeatures(degree=3, include_bias=False)
X = hz128

# X_poly: 各特徴量の３乗と２乗を新特徴量として訓練セットに追加する。
X_poly = poly_features.fit_transform(X.reshape(-1, 1))
# 拡張訓練データをモデルに適合させる
line_reg = LinearRegression()
line_reg.fit(X_poly, cs128_abs)


line_reg.coef_[2]


X_poly[1]


# 表示
plt.plot(X, cs128_abs)

y_poly_fit = line_reg.coef_[2]*X_poly[:, 2] + line_reg.coef_[1]*X_poly[:, 1] + line_reg.coef_[0]*X_poly[:, 0] + line_reg.intercept_
plt.plot(X, y_poly_fit)

plt.show()


coe = np.polyfit(hz128, cs128_abs, 3)
print(coe)


# 結果を表示
plt.plot(hz128, cs128_abs)

poly_fit_res_polyfit = coe[0] * hz128**3 + coe[1] * hz128**2 + coe[2] * hz128 + coe[3]
plt.plot(hz128, poly_fit_res_polyfit)

plt.show()


# 相関関数と決定係数
r_scikit = np.corrcoef(cs128_abs, y_poly_fit)[0][1]
r2_scikit = r_scikit**2
print(r2_scikit)


r_polyfit = np.corrcoef(cs128_abs, poly_fit_res_polyfit)[0][1]
r2_polyfit = r_polyfit ** 2
print(r2_polyfit)


from scipy import signal


def fft(y, dt):
    spec = sfft.fft(y) # フーリエスペクトル（複素数）
    freq = sfft.fftfreq(len(spec), d=dt) # 周波数軸を生成
    amp = np.sqrt(spec.real**2 + spec.imag**2) / (len(spec)/2) # 振幅を計算
    return spec, amp, freq


spec = sfft.fft(v)
# specplus = [i for i in amp if (i >= 0)]


# sample wave
dt = 0.0001
t = np.arange(0, 10, dt)
noise = 1 * np.random.normal(loc=0, scale=1, size=len(t)) # 平均loc, 標準偏差scaleの正規分布に従う乱数を返す
y = signal.sawtooth(2 * np.pi * 1 * t) + noise


# フーリエ変換する
# spec, amp, freq = fft(y, dt)

y = v
dt = 1/fs
t = np.arange(0, len(v)/fs, dt)
spec, amp, freq = fft(v, dt)


plt.plot(t, y)


# 波形(x, y)からn個のピークを幅wで検出する関数(xは0から始まる仕様）
# x, y: 波形
# n: 抽出するピーク数
# w: ピーク感度に関する幅
def findpeaks(x, y, n, w):
    index_all = list(signal.argrelmax(y, order=w))                  # scipyのピーク検出
    index = []                                                      # ピーク指標の空リスト
    peaks = []                                                     # ピーク値の空リスト

    # n個分のピーク情報(指標、値）を格納
    for i in range(n):
        # ピークがn個に満たない場合、ループを抜ける（エラー処理）
        if i >= len(index_all[0]):
            break
        index.append(index_all[0][i])
        peaks.append(y[index_all[0][i]])
        
    # 個数の足りない分を0で埋める（エラー処理）
    if len(index) != n:
        index = index + ([0] * (n - len(index)))
        peaks = peaks + ([0] * (n - len(peaks)))
    
    ix_val = np.array(index) * x[1]                                  # xの分解能x[1]をかけて指標を物理軸に変換
    return ix_val, peaks, index, index_all
#     return index, peaks


import heapq
import math


# 最大ピークを検出する関数
def findMaxPeak(x, y, w):
    all_index = list(signal.argrelmax(y, order=w))
    all_index = all_index[0]
    vals = y[all_index]
    
    # 最大値を取得
    max_val = max(vals)
    # 最大値のインデックス
    max_index = all_index[np.argmax(vals)]
    
    return max_index, all_index, max_val


# 基準インデックスから周囲ms_range[s]の波形を切り出す
def getWaveWithinTimeRange(x, y, base_ix, sec_range, fs):
    dt = 1.0/fs  # インデックス間の時間間隔
    # 切り出す範囲のインデックスを計算
    delta_ix = math.floor(sec_range/dt)
    start_ix = base_ix - delta_ix
    end_ix = base_ix + delta_ix
    
    # 範囲外のインデックスに対する処理
    if start_ix < 0:
        start_ix = 0
    if end_ix > len(y)-1:
        end_ix = len(y) - 1
    
    index = np.arange(start_ix, end_ix+1)
    val = y[index]
    
    return index, val


# 最大ピークと10ms以内の他のピークの平均値の比を取得する関数
# x, y: 波形
# w: ピーク検出における感度
# ms_range: 切り出す時間範囲
def getRatioMaxToOtherAvePeaks(x, y, w, fs, sec_range=0.01):
    # 最大ピークとその時のインデックスを取得
    max_ix, all_ix, max_val = findMaxPeak(x, y, w)
    
    # max_indexから+-10ms以内の波形を切り出す。
    # target_ix : 対象時間区間のインデックス（ピークとピークでないものも含む）
    # target_val : target_ixに対応する値
    target_ix, target_val = getWaveWithinTimeRange(x, y, max_ix, sec_range, fs)
    
    # target_peak_ix : 対象時間範囲内のピーク部分に対応するインデックス
    target_peak_ix = [i for i in all_ix if (i >= target_ix[0]) and (i <= target_ix[-1]) and (i != max_ix)]
    
    # 最大ピーク以外の他の全てのピークの平均値を算出
    mean_other_peaks = np.mean(y[target_peak_ix])
    
    # 結果の確認
    max_t = 1/fs*max_ix
    peak_t = [1/fs*i for i in target_peak_ix]
    plt.plot(x, y)
    plt.scatter(max_t, max_val, color='red')
    plt.scatter(peak_t, y[target_peak_ix], color='green')
    plt.show()
    plt.close()
    
    # 比率の計算
    ratio = mean_other_peaks/max_val
    return ratio


getRatioMaxToOtherAvePeaks(t, v, 3, fs)


vabs = np.abs(v)
getRatioMaxToOtherAvePeaks(t, vabs, 3, fs)


nlist = np.arange(10)
nlist2 = [i for i in nlist if i>2 and i<9 and i%2==0]
nlist2


# 第n位の大きさのピークの値を取得
# 波形(x, y)
# n: 第n位の大きさのピークまで抽出する
# w: ピーク感度に関する幅
def findNthMaxPeak(x, y, n, w):
    index_all = list(signal.argrelmax(y, order=w))
    index_all = index_all[0]
    vals = y[index_all]
    
    # 検出したピークの個数がn個に満たない場合
    if len(index_all) < n:
        return vals.tolist()
    
    peak_vals = heapq.nlargest(n, vals)
    return peak_vals


def getRatioMaxToNthAvePeaks(x, y, w, fs, n=10):
    peak_vals = findNthMaxPeak(x, y, n, w)
    max_peak_val = max(peak_vals)
    # 最大ピークと次に高いn-1個のピークのlist
    peak_vals.remove(max_peak_val)
    # 平均値
    mean_peak_val = np.mean(peak_vals)
    # 比率を算出
    ratio = mean_peak_val / max_peak_val
    
    return ratio


getRatioMaxToNthAvePeaks(t, v, 3, fs)


plt.plot(t, v)


import random
numlist = np.random.randint(0, 20, 8)
heapq.nlargest(3, numlist)


type(numlist)


l = list(range(10))
m = l.remove(0)
m


# フォントの種類とサイズの設定
plt.rcParams['font.size'] = 14
plt.rcParams['font.family'] = 'Times New Roman'

# 目盛りを内側にする
plt.rcParams['xtick.direction'] = 'in'
plt.rcParams['ytick.direction'] = 'in'

# グラフの上下左右に目盛りを付ける
fig = plt.figure(figsize=(8, 5))
ax1 = fig.add_subplot(211)
ax1.yaxis.set_ticks_position('both')
ax1.xaxis.set_ticks_position('both')
ax2 = fig.add_subplot(212)
ax2.yaxis.set_ticks_position('both')
ax2.xaxis.set_ticks_position('both')

# 軸のラベルを設定する
ax1.set_xlabel('Time[s]')
ax1.set_ylabel('Amp.')
ax2.set_xlabel('Frequency[Hz]')
ax2.set_ylabel('Amp.')

# スケール設定
# ax2.set_xlim(0, 10)
# ax2.set_yscale('log')

# データプロットの準備と共に、ラベルと線の太さ、凡例の設定を行う
ax1.plot(t, y, label='sample', lw=1)
ax1.legend()

# peaksを算出していないため、コメントアウト
# ax2.plot(freq[:int(len(freq)/2)], amp[:int(len(freq)/2)], label='sample', lw=1)
# ax2.scatter(index, peaks, label='peaks', color='red')
# ax2.legend()

# レイアウト設定
fig.tight_layout()

# グラフを表示する
plt.show()
plt.close()


# 自己相関を計算
yc = np.correlate(v, v, "full")


plt.plot(yc)
plt.axhline(0, ls="-.", color="magenta")
plt.show()


# 拡大表示
plt.plot(yc[fs-4:fs])
plt.axhline(0, ls="-.", color="magenta")
plt.show()


fs


# 標準偏差
yc_std = np.std(yc)
yc_std


yc


# 曲線下面積を求める
# x軸がインデックスであることを前提とする。
def calcAUC(y):
    # 総面積
    S = 0
    
    for i in range(0, len(y)):
        S += np.abs(y[i]) * 1
    
    return S


calcAUC(yc)


x = np.arange(-2, 2, 0.001)
f = x


plt.plot(x, f)
plt.axhline(0, ls="-.", color="magenta")
plt.show()


# 微分値を求める
# x軸がインデックス
def calcDiffer(y):
    differs = []
    for i in range(0, len(y)-1):
        d = np.abs((y[i+1] - y[i])/1)
        differs.append(d)
    return differs


yc_diff = calcDiffer(yc)


plt.plot(yc_diff)
plt.show()


plt.plot(yc)
plt.show()


yc_diff_std = np.std(yc_diff)
yc_diff_std


calcAUC(yc_diff)


from srmrpy.srmr import *


srmr(v, fs)


# GCC-PHATを算出
def gcc_phat(sig, refsig, fs=1, max_tau=None, interp=16):
    '''
    This function computes the offset between the signal sig and the reference signal refsig
    using the Generalized Cross Correlation - Phase Transform (GCC-PHAT)method.
    '''

    # make sure the length for the FFT is larger or equal than len(sig) + len(refsig)
    n = sig.shape[0] + refsig.shape[0]

    # Generalized Cross Correlation Phase Transform
    SIG = np.fft.rfft(sig, n=n)
    REFSIG = np.fft.rfft(refsig, n=n)
    R = SIG * np.conj(REFSIG)

    # 純粋なGCC-PHATの値はこれ。
    cc = np.fft.irfft(R / np.abs(R), n=(interp * n))
    
    return cc, n


# GCC-PHATをフィルタにTDOA(Time Difference Of Arrival)を算出する
def tdoa_from_gccphat(cc, n, fs=1, max_tau=None, interp=16):
    max_shift = int(interp * n / 2)
    if max_tau:
        max_shift = np.minimum(int(interp * fs * max_tau), max_shift)

    cc = np.concatenate((cc[-max_shift:], cc[:max_shift+1]))

    # find max cross correlation index
    shift = np.argmax(np.abs(cc)) - max_shift

    tau = shift / float(interp * fs)

    return tau, cc


# 直交するマイク間の距離に基づく理論上の最大遅延[s]
MAX_DELAY = 0.000236

# 音声データの最大ピーク検出
max_index, _, _ = findMaxPeak(t, v, 3)
# +-MAX_DELAYだけ切り出す
max_delay_ix, max_delay_val = getWaveWithinTimeRange(t, v, max_index, MAX_DELAY, fs)

# 同様
max_index2, _, _ = findMaxPeak(t2, v2, 3)
max_delay_ix2, max_delay_val2 = getWaveWithinTimeRange(t2, v2, max_index2, MAX_DELAY, fs2)


sound_speed = 343.2
distance = 0.14

# max_tauは時間
max_tau = distance / sound_speed

# GCC-PHATの計算
cc, n = gcc_phat(max_delay_val, max_delay_val2, fs=fs)


gp_ix = np.arange(len(cc))


# GCC-PHATの最大ピークを計算
gp_max_ix, _, gp_max_val = findMaxPeak(gp_ix, cc, 3)


gp_s = calcAUC(cc)
gp_s


tdoa = tdoa_from_gccphat(cc, n, fs=fs, max_tau=max_tau)
tdoa
